# -*- coding: utf-8 -*-
"""lstm_vincent.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CUheatmYHzHID9QGKUbqrPrFq8sdcc5z
"""

# import libraries
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
# import keras modules
from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator
from tensorflow.keras import backend as K
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model

# import additional modules
from statistics import mean
from math import sqrt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.layers import concatenate
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM,GRU
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras import backend as K
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import InputLayer, Input
from tensorflow.keras.layers import Reshape, MaxPooling2D
from tensorflow.keras.layers import Conv2D, Dense, Flatten
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model


# function to transform time series to supervised learning series
from pandas import DataFrame
from pandas import concat

# load dataset
def split_cal_val(x, cal_start , cal_end , val_start, val_end):
  
  # Cette fonction prend en argument les dates de début et de fin du calage et de la validation
  # Ces dates sont pris en tant que chaine de caractère 
  # Voici un exemple cal_start=  '01/01/1965'

  # La fonction retourne les données de calage et de  validation 
  a = x[x['Dates'] == cal_start].index
  a = int(a.values)
  b = x[x['Dates'] == cal_end].index
  b = int(b.values) 

  cal_data = x.iloc[a:b+1] 

  c = x[x['Dates'] == val_start].index
  c = int(c.values)
  d = x[x['Dates'] == val_end].index
  d = int(d.values) 

  val_data = x.iloc[c:d+1]

  return ( cal_data, val_data)

# Modèles LSTM

#set default parameter values for lstm model

learning_rate = 1e-2
num_lstm_units = 100
num_epochs=10
num_batch_size= 100


# define a helper-function for log-dir-name
def log_dir_name(learning_rate, num_lstm_units,
                 num_epochs, num_batch_size):

    # the dir-name for the TensorBoard log-dir
    s = "./5_logs/lr_{0:.0e}_lstm_{1}_epochs_{2}_batch_{3}/"

    # insert all the hyper-parameters in the dir-name
    log_dir = s.format(learning_rate,
                       num_lstm_units,
                       num_epochs,
                       num_batch_size)

    return log_dir

def preprocessing(df):
    # select values of dataframe
    values = df.values

    # remove output data y to rescale later
    values_x = np.delete(values, -1, axis=1)
    values_x.shape

    # rescale data between 0 and 1
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_x = scaler.fit_transform(values_x)
    # select values of output data y
    values_y = values[:, -1]

    # rescale manually output data y
    scaled_y = (values_y -values_y.mean())/ values_y.std()
    # reshape scaled date to concatenate with scaled input data
    scaled_y = scaled_y.reshape((scaled_y.shape[0], 1))

    # concatenate input data x and output data y
    scaled = np.concatenate((scaled_x, scaled_y), axis=1)
    return  scaled
